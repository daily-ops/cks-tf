# -*- mode: ruby -*-
# vi:set ft=ruby sw=2 ts=2 sts=2:

# Set the build mode
# "BRIDGE" - Places VMs on your local network so cluster can be accessed from browser.
#            You must have enough spare IPs on your network for the cluster nodes.
# "NAT"    - Places VMs in a private virtual network. Cluster cannot be accessed
#            without setting up a port forwarding rule for every NodePort exposed.
#            Use this mode if for some reason BRIDGE doesn't work for you.
BUILD_MODE = "BRIDGE"

# Define the number of worker nodes
# If this number is changed, remember to update setup-hosts.sh script with the new hosts IP details in /etc/hosts of each VM.
NUM_WORKER_NODES = 0

# Network parameters for NAT mode
IP_NW = "192.168.0"
MASTER_IP_START = 180
NODE_IP_START = 185

# Host operating sysem detection
module OS
  def OS.windows?
    (/cygwin|mswin|mingw|bccwin|wince|emx/ =~ RUBY_PLATFORM) != nil
  end

  def OS.mac?
    (/darwin/ =~ RUBY_PLATFORM) != nil
  end

  def OS.unix?
    !OS.windows?
  end

  def OS.linux?
    OS.unix? and not OS.mac?
  end

  def OS.jruby?
    RUBY_ENGINE == "jruby"
  end
end

# Determine host adpater for bridging in BRIDGE mode
def get_bridge_adapter()
  if OS.windows?
    return %x{powershell -Command "Get-NetRoute -DestinationPrefix 0.0.0.0/0 | Get-NetAdapter | Select-Object -ExpandProperty InterfaceDescription"}.chomp
  elsif OS.linux?
    return %x{ip route | grep default | awk '{ print $5 }' | grep -v -e "^wl"}.chomp
  elsif OS.mac?
    return %x{mac/mac-bridge.sh}.chomp
  end
end

# Helper method to get the machine ID of a node.
# This will only be present if the node has been
# created in VirtualBox.
def get_machine_id(vm_name)
  machine_id_filepath = ".vagrant/machines/#{vm_name}/virtualbox/id"
  if not File.exist? machine_id_filepath
    return nil
  else
    return File.read(machine_id_filepath)
  end
end

# Helper method to determine whether all nodes are up
def all_nodes_up()
  if get_machine_id("kubernetes").nil?
    return false
  end

  (1..NUM_WORKER_NODES).each do |i|
    if get_machine_id("node0#{i}").nil?
      return false
    end
  end
  return true
end

# Sets up hosts file and DNS
def setup_dns(node)
  # Set up /etc/hosts
  node.vm.provision "setup-hosts", :type => "shell", :path => "ubuntu/vagrant/setup-hosts.sh" do |s|
    s.args = [IP_NW, BUILD_MODE, NUM_WORKER_NODES, MASTER_IP_START, NODE_IP_START]
  end
  # Set up DNS resolution
  node.vm.provision "setup-dns", type: "shell", :path => "ubuntu/update-dns.sh"
end

# Runs provisioning steps that are required by masters and workers
def provision_kubernetes_node(node)
  # Set up DNS
  setup_dns node
  # Set up ssh
  node.vm.provision "setup-ssh", :type => "shell", :path => "ubuntu/ssh.sh"
end

# All Vagrant configuration is done below. The "2" in Vagrant.configure
# configures the configuration version (we support older styles for
# backwards compatibility). Please don't change it unless you know what
# you're doing.
Vagrant.configure("2") do |config|
  # The most common configuration options are documented and commented below.
  # For a complete reference, please see the online documentation at
  # https://docs.vagrantup.com.

  # Every Vagrant development environment requires a box. You can search for
  # boxes at https://vagrantcloud.com/search.
  # config.vm.box = "base"

  config.vm.box = "ubuntu/jammy64"
  config.vm.boot_timeout = 900


  # Disable automatic box update checking. If you disable this, then
  # boxes will only be checked for updates when the user runs
  # `vagrant box outdated`. This is not recommended.
  config.vm.box_check_update = false

  # Provision Master Nodes
  config.vm.define "kubernetes" do |node|
    # Name shown in the GUI
    node.vm.provider "virtualbox" do |vb|
      vb.name = "kubernetes"
      vb.memory = 2048
      vb.cpus = 2
    end
    node.vm.hostname = "kubernetes"
    if BUILD_MODE == "BRIDGE"
      adapter = ""
      node.vm.network :public_network, bridge: get_bridge_adapter(), ip: IP_NW + ".#{MASTER_IP_START}"
    else
      node.vm.network :private_network, ip: IP_NW + ".#{MASTER_IP_START}"
      node.vm.network "forwarded_port", guest: 22, host: "#{2710}"
    end
    provision_kubernetes_node node

    if BUILD_MODE == "BRIDGE"
      node.vm.provision "shell", inline: "useradd -s /bin/bash -m ansible"
      node.vm.provision "file", source: "~/.ssh/id_rsa.pub", destination: "/tmp/authorized_keys"
      node.vm.provision "shell", inline: "mkdir /home/ansible/.ssh && mv /tmp/authorized_keys /home/ansible/.ssh/ && chown ansible:ansible /home/ansible/.ssh/authorized_keys"
    end

    if BUILD_MODE == "BRIDGE"
        node.trigger.after :up do |trigger|
          trigger.info = "Append master node to known_hosts file"
          tmp_ip = IP_NW + ".#{MASTER_IP_START}"

          trigger.run = {path: "./ubuntu/ansible/known_hosts.sh", args: "#{tmp_ip}"}
        end
    end
  end


  # Provision Worker Nodes
  (1..NUM_WORKER_NODES).each do |i|
    config.vm.define "node0#{i}" do |node|
      node.vm.provider "virtualbox" do |vb|
        vb.name = "node0#{i}"
        vb.memory = 1024
        vb.cpus = 1
      end
      node.vm.hostname = "node0#{i}"
      if BUILD_MODE == "BRIDGE"
        node.vm.network :public_network, bridge: get_bridge_adapter(), ip: IP_NW + ".#{NODE_IP_START + i}"
      else
        node.vm.network :private_network, ip: IP_NW + ".#{NODE_IP_START + i}"
        node.vm.network "forwarded_port", guest: 22, host: "#{2720 + i}"
      end
      provision_kubernetes_node node

      if BUILD_MODE == "BRIDGE"
        node.vm.provision "shell", inline: "useradd -s /bin/bash -m ansible"
        node.vm.provision "file", source: "~/.ssh/id_rsa.pub", destination: "/tmp/authorized_keys"
        node.vm.provision "shell", inline: "mkdir /home/ansible/.ssh && mv /tmp/authorized_keys /home/ansible/.ssh/ && chown ansible:ansible /home/ansible/.ssh/authorized_keys"
        node.vm.provision :shell do |s|
          s.path = 'ubuntu/ansible/setup.sh'
        end
      end
      node.vm.provision :shell do |s|
        s.path = 'ubuntu/setup-kernel.sh'
      end

      if BUILD_MODE == "BRIDGE"
        node.trigger.after :up do |trigger|
          trigger.info = "Append node to known_hosts file"
          tmp_ip = IP_NW + ".#{NODE_IP_START + i}"
          trigger.run = {path: "./ubuntu/ansible/known_hosts.sh", args: "#{tmp_ip}"}
        end
      end
    end
  end

  if BUILD_MODE == "BRIDGE"
    # Trigger that fires after each VM starts.
    # Does nothing until all the VMs have started, at which point it
    # gathers the IP addresses assigned to the bridge interfaces by DHCP
    # and pushes a hosts file to each node with these IPs.
    config.trigger.after :up do |trigger|
      trigger.name = "Post provisioner"
      trigger.ignore = [:destroy, :halt]
      trigger.ruby do |env, machine|
        if all_nodes_up()
          puts "    Gathering IP addresses of nodes..."
          ips = []
          nodes = ["kubernetes"]
          ips.push(IP_NW + ".#{MASTER_IP_START}")
          (1..NUM_WORKER_NODES).each do |i|
            nodes.push("node0#{i}")
            ips.push(IP_NW + ".#{NODE_IP_START + i}")
          end

          hosts = ""
          ips.each_with_index do |ip, i|
            hosts << ip << "  " << nodes[i] << "\n"
          end
          puts "    Setting /etc/hosts on nodes..."
          File.open("hosts.tmp", "w") { |file| file.write(hosts) }
          nodes.each do |node|
            system("vagrant upload hosts.tmp /tmp/hosts.tmp #{node}")
            system("vagrant ssh #{node} -c 'cat /tmp/hosts.tmp | sudo tee -a /etc/hosts'")
          end
          File.delete("hosts.tmp")

          puts "Populate ansible inventory at ubuntu/ansible/inventory"
          nodes_group = ""
          nodes_group << "[master]" << "\n"

          tmp_ip = IP_NW + ".#{MASTER_IP_START}"
          nodes_group << IP_NW + ".#{MASTER_IP_START}" << "\n\n"

          nodes_group << "[workers]" << "\n"
          (1..NUM_WORKER_NODES).each do |i|
            tmp_ip = IP_NW + ".#{NODE_IP_START + i}"
            nodes_group << IP_NW + ".#{NODE_IP_START + i}" << "\n"
          end

          File.open("ubuntu/ansible/inventory", "w") { |file| file.write(nodes_group) }

          puts "    You may now use the inventory to manage the boxes:"
          puts "        ansible -i ubuntu/ansible/inventory -m ping all"
          puts "        ansible -i ubuntu/ansible/inventory -m ping master"
          puts "        ansible -i ubuntu/ansible/inventory -m ping workers"

          puts <<~EOF

                 VM build complete!

                 Use either of the following to access any NodePort services you create from your browser
                 replacing "port_number" with the number of your NodePort.

               EOF
          (1..NUM_WORKER_NODES).each do |i|
            puts "  http://#{ips[i]}:port_number"
          end
          puts ""
        else
          puts "    Nothing to do here"
        end
      end
    end
  end
end
